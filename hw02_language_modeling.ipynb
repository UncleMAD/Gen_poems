{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
    "\n",
    "Ваша основная задача: научиться генерироват стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.339251Z",
     "start_time": "2025-05-06T16:46:09.333325Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import string\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.449717Z",
     "start_time": "2025-05-06T16:46:09.440269Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('{} device is available'.format(device))\n",
    "# __________end of block__________"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu device is available\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPenWOy01Ooa",
    "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
   },
   "source": [
    "#### 1. Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.470302Z",
     "start_time": "2025-05-06T16:46:09.454735Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "# !curl -O https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
    "    \n",
    "with open('onegin.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XQYpmGfR_gJ8"
   },
   "source": [
    "#### 2. Построение словаря и предобработка текста\n",
    "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим токен `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.559979Z",
     "start_time": "2025-05-06T16:46:09.518318Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "tokens = sorted(set(text.lower())) + ['<sos>']\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "assert num_tokens == 84, \"Check the tokenization process\"\n",
    "\n",
    "token_to_idx = {x: idx for idx, x in enumerate(tokens)}\n",
    "idx_to_token = {idx: x for idx, x in enumerate(tokens)}\n",
    "\n",
    "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
    "\n",
    "print(\"Seems fine!\")\n",
    "\n",
    "\n",
    "text_encoded = [token_to_idx[x] for x in text]\n",
    "# __________end of block__________"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
    "\n",
    "Вы можете воспользоваться кодом с занятие №6 или же обратиться к следующим ссылкам:\n",
    "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
    "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
    "\n",
    "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
    "\n",
    "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.589285Z",
     "start_time": "2025-05-06T16:46:09.581990Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "batch_size = 256\n",
    "seq_length = 100\n",
    "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx['<sos>']\n",
    "\n",
    "def generate_chunk():\n",
    "    global text_encoded, start_column, batch_size, seq_length\n",
    "\n",
    "    start_index = np.random.randint(0, len(text_encoded) - batch_size*seq_length - 1)\n",
    "    data = np.array(text_encoded[start_index:start_index + batch_size*seq_length]).reshape((batch_size, -1))\n",
    "    yield np.hstack((start_column, data))\n",
    "# __________end of block__________    "
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример батча:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.630220Z",
     "start_time": "2025-05-06T16:46:09.613299Z"
    }
   },
   "source": [
    "next(generate_chunk())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83,  1, 60, ..., 73, 76,  0],\n",
       "       [83, 49, 59, ..., 50, 54, 13],\n",
       "       [83,  0, 58, ..., 47, 64, 76],\n",
       "       ...,\n",
       "       [83, 76, 47, ...,  1, 48, 56],\n",
       "       [83, 76, 49, ...,  0, 62, 63],\n",
       "       [83, 45, 61, ..., 56, 50, 58]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее вам предстоит написать код для обучения модели и генерации текста."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:05:05.110235Z",
     "start_time": "2025-05-06T17:05:05.100377Z"
    }
   },
   "source": [
    "# your beautiful experiments here\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, num_tokens, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embed = nn.Embedding(num_tokens, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_tokens)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:05:24.409124Z",
     "start_time": "2025-05-06T17:05:21.438524Z"
    }
   },
   "source": [
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "model = CharRNN(num_tokens, hidden_size, num_layers).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:05:34.456549Z",
     "start_time": "2025-05-06T17:05:34.444441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for _ in range(100):  # 100 итераций на эпоху\n",
    "            batch = next(generate_chunk())\n",
    "            inputs = torch.tensor(batch[:, :-1], dtype=torch.long).to(device)\n",
    "            targets = torch.tensor(batch[:, 1:], dtype=torch.long).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, num_tokens), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}: loss = {total_loss / 100:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.786746Z",
     "start_time": "2025-05-06T16:46:09.777762Z"
    }
   },
   "source": [
    "def generate_sample(char_rnn, seed_phrase=None, max_length=200, temperature=1.0, device=device):\n",
    "    if seed_phrase is not None:\n",
    "        x_sequence = [token_to_idx['<sos>']] + [token_to_idx[token] for token in seed_phrase]\n",
    "    else:\n",
    "        x_sequence = [token_to_idx['<sos>']]\n",
    "\n",
    "    x = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
    "    hidden = None\n",
    "    output_sequence = x_sequence.copy()\n",
    "\n",
    "    for _ in range(max_length - len(x_sequence)):\n",
    "        out, hidden = char_rnn(x[:, -1:].to(device), hidden)\n",
    "        out = out[:, -1, :] / temperature\n",
    "        probs = F.softmax(out, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        output_sequence.append(next_token)\n",
    "        x = torch.tensor([[next_token]], dtype=torch.int64).to(device)\n",
    "\n",
    "    return ''.join([idx_to_token[ix] for ix in output_sequence[1:]])\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-06T17:06:53.705453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train(model, epochs=10)  # можно больше\n",
    "\n",
    "seed_phrase = ' мой дядя самых честных правил'\n",
    "generated_phrases = [\n",
    "    generate_sample(model, seed_phrase, max_length=500, temperature=0.8).replace('<sos>', '')\n",
    "    for _ in range(10)\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.830721Z",
     "start_time": "2025-05-06T16:46:09.802767Z"
    }
   },
   "source": [
    "print(generate_sample(model, ' мой дядя самых честных правил', max_length=500, temperature=0.8))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(generate_sample(model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m мой дядя самых честных правил\u001B[39m\u001B[38;5;124m'\u001B[39m, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m, temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
    "\n",
    "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.850102Z",
     "start_time": "2025-05-06T16:46:09.843735Z"
    }
   },
   "source": [
    "seed_phrase = ' мой дядя самых честных правил'"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.874960Z",
     "start_time": "2025-05-06T16:46:09.867115Z"
    }
   },
   "source": [
    "generated_phrases = # your code here\n",
    "\n",
    "# For example:\n",
    "\n",
    "# generated_phrases = [\n",
    "#     generate_sample(\n",
    "#         model,\n",
    "#         ' мой дядя самых честных правил',\n",
    "#         max_length=500,\n",
    "#         temperature=1.\n",
    "#     ).replace('<sos>', '')\n",
    "#     for _ in range(10)\n",
    "# ]"
   ],
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3861625285.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[20], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    generated_phrases = # your code here\u001B[0m\n\u001B[1;37m                        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:46:09.947139Z",
     "start_time": "2025-05-06T16:46:09.911973Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "import json\n",
    "if 'generated_phrases' not in locals():\n",
    "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
    "\n",
    "for phrase in generated_phrases:\n",
    "\n",
    "    if not isinstance(phrase, str):\n",
    "        raise ValueError(\"The generated phrase should be a string\")\n",
    "\n",
    "    if len(phrase) != 500:\n",
    "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
    "\n",
    "    assert all([x in set(tokens) for x in set(list(phrase))]), 'Unknown tokens detected, check your submission!'\n",
    "    \n",
    "\n",
    "submission_dict = {\n",
    "    'token_to_idx': token_to_idx,\n",
    "    'generated_phrases': generated_phrases\n",
    "}\n",
    "\n",
    "with open('submission_dict.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print('File saved to `submission_dict.json`')\n",
    "# __________end of block__________"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please, save generated phrases to `generated_phrases` variable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenerated_phrases\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlocals\u001B[39m():\n\u001B[1;32m----> 6\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease, save generated phrases to `generated_phrases` variable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m phrase \u001B[38;5;129;01min\u001B[39;00m generated_phrases:\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(phrase, \u001B[38;5;28mstr\u001B[39m):\n",
      "\u001B[1;31mValueError\u001B[0m: Please, save generated phrases to `generated_phrases` variable"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "NLP HW Lab01_Poetry_generation.v5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
