{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
    "\n",
    "Ваша основная задача: научиться генерироват стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:28:46.875363Z",
     "start_time": "2025-05-06T17:28:46.867173Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import string\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:28:47.003262Z",
     "start_time": "2025-05-06T17:28:46.999328Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('{} device is available'.format(device))\n",
    "# __________end of block__________"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device is available\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPenWOy01Ooa",
    "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
   },
   "source": [
    "#### 1. Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:28:47.042733Z",
     "start_time": "2025-05-06T17:28:47.031259Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "# !curl -O https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
    "    \n",
    "with open('onegin.txt', 'r', encoding='utf-8') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XQYpmGfR_gJ8"
   },
   "source": [
    "#### 2. Построение словаря и предобработка текста\n",
    "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим токен `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:28:47.105579Z",
     "start_time": "2025-05-06T17:28:47.057732Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "tokens = sorted(set(text.lower())) + ['<sos>']\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "assert num_tokens == 84, \"Check the tokenization process\"\n",
    "\n",
    "token_to_idx = {x: idx for idx, x in enumerate(tokens)}\n",
    "idx_to_token = {idx: x for idx, x in enumerate(tokens)}\n",
    "\n",
    "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
    "\n",
    "print(\"Seems fine!\")\n",
    "\n",
    "\n",
    "text_encoded = [token_to_idx[x] for x in text]\n",
    "# __________end of block__________"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
    "\n",
    "Вы можете воспользоваться кодом с занятие №6 или же обратиться к следующим ссылкам:\n",
    "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
    "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
    "\n",
    "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
    "\n",
    "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:28:47.137162Z",
     "start_time": "2025-05-06T17:28:47.113580Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "batch_size = 256\n",
    "seq_length = 100\n",
    "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx['<sos>']\n",
    "\n",
    "def generate_chunk():\n",
    "    global text_encoded, start_column, batch_size, seq_length\n",
    "\n",
    "    start_index = np.random.randint(0, len(text_encoded) - batch_size*seq_length - 1)\n",
    "    data = np.array(text_encoded[start_index:start_index + batch_size*seq_length]).reshape((batch_size, -1))\n",
    "    yield np.hstack((start_column, data))\n",
    "# __________end of block__________    "
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример батча:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:28:47.192655Z",
     "start_time": "2025-05-06T17:28:47.141165Z"
    }
   },
   "source": [
    "next(generate_chunk())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83,  5,  0, ...,  1, 76,  1],\n",
       "       [83, 47, 50, ..., 61,  1, 59],\n",
       "       [83, 62, 63, ...,  1, 59, 46],\n",
       "       ...,\n",
       "       [83, 47, 45, ..., 57,  1, 69],\n",
       "       [83, 45, 63, ..., 64, 62, 55],\n",
       "       [83, 45, 50, ..., 63,  5,  1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее вам предстоит написать код для обучения модели и генерации текста."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:45:56.695852Z",
     "start_time": "2025-05-06T17:45:56.689781Z"
    }
   },
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, num_tokens, hidden_size, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embed = nn.Embedding(num_tokens, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers,\n",
    "                            dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_tokens)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.num_layers, batch_size, self.hidden_size),\n",
    "                weight.new_zeros(self.num_layers, batch_size, self.hidden_size))\n"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:47:18.854020Z",
     "start_time": "2025-05-06T17:47:18.836170Z"
    }
   },
   "source": [
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "\n",
    "model = CharRNN(num_tokens=num_tokens, hidden_size=hidden_size,\n",
    "                num_layers=num_layers, dropout=dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:46:15.270967Z",
     "start_time": "2025-05-06T17:46:15.263950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, epochs=20, patience=3):\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for _ in range(100):\n",
    "            batch = next(generate_chunk())\n",
    "            inputs = torch.tensor(batch[:, :-1], dtype=torch.long).to(device)\n",
    "            targets = torch.tensor(batch[:, 1:], dtype=torch.long).to(device)\n",
    "\n",
    "            hidden = model.init_hidden(inputs.size(0))  # batch_size\n",
    "            hidden = tuple(h.to(device) for h in hidden)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            loss = criterion(outputs.view(-1, num_tokens), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / 100\n",
    "        print(f\"Epoch {epoch + 1}: loss = {avg_loss:.4f}\")\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:46:32.398016Z",
     "start_time": "2025-05-06T17:46:32.390641Z"
    }
   },
   "source": [
    "def generate_sample(model, seed_phrase=None, max_length=200, temperature=1.0, device=device):\n",
    "    model.eval()\n",
    "\n",
    "    if seed_phrase:\n",
    "        x_sequence = [token_to_idx['<sos>']] + [token_to_idx[c] for c in seed_phrase]\n",
    "    else:\n",
    "        x_sequence = [token_to_idx['<sos>']]\n",
    "\n",
    "    input_seq = torch.tensor([[x_sequence[0]]], dtype=torch.long).to(device)\n",
    "    hidden = model.init_hidden(1)\n",
    "    hidden = tuple(h.to(device) for h in hidden)\n",
    "\n",
    "    generated = []\n",
    "\n",
    "    # прогоняем seed_phrase\n",
    "    for idx in x_sequence:\n",
    "        input_seq = torch.tensor([[idx]], dtype=torch.long).to(device)\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "\n",
    "    idx = x_sequence[-1]\n",
    "\n",
    "    for _ in range(max_length - len(x_sequence)):\n",
    "        input_seq = torch.tensor([[idx]], dtype=torch.long).to(device)\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        output = output[:, -1, :] / temperature\n",
    "        probabilities = F.softmax(output, dim=-1).detach().cpu().numpy().flatten()\n",
    "        idx = np.random.choice(len(probabilities), p=probabilities)\n",
    "        generated.append(idx)\n",
    "\n",
    "    full_sequence = x_sequence + generated\n",
    "    return ''.join([idx_to_token[i] for i in full_sequence if idx_to_token[i] != '<sos>'])\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:50:48.954599Z",
     "start_time": "2025-05-06T17:47:24.835485Z"
    }
   },
   "cell_type": "code",
   "source": "train(model, epochs=50, patience=5)\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 2.6093\n",
      "Epoch 2: loss = 2.0562\n",
      "Epoch 3: loss = 1.8490\n",
      "Epoch 4: loss = 1.6954\n",
      "Epoch 5: loss = 1.5841\n",
      "Epoch 6: loss = 1.4786\n",
      "Epoch 7: loss = 1.3757\n",
      "Epoch 8: loss = 1.3038\n",
      "Epoch 9: loss = 1.2056\n",
      "Epoch 10: loss = 1.1472\n",
      "Epoch 11: loss = 1.1086\n",
      "Epoch 12: loss = 1.0487\n",
      "Epoch 13: loss = 0.9914\n",
      "Epoch 14: loss = 0.9341\n",
      "Epoch 15: loss = 0.9195\n",
      "Epoch 16: loss = 0.8985\n",
      "Epoch 17: loss = 0.8584\n",
      "Epoch 18: loss = 0.8627\n",
      "Epoch 19: loss = 0.8059\n",
      "Epoch 20: loss = 0.7969\n",
      "Epoch 21: loss = 0.7745\n",
      "Epoch 22: loss = 0.7578\n",
      "Epoch 23: loss = 0.7436\n",
      "Epoch 24: loss = 0.7250\n",
      "Epoch 25: loss = 0.7143\n",
      "Epoch 26: loss = 0.6837\n",
      "Epoch 27: loss = 0.6928\n",
      "Epoch 28: loss = 0.6981\n",
      "Epoch 29: loss = 0.6650\n",
      "Epoch 30: loss = 0.6474\n",
      "Epoch 31: loss = 0.6692\n",
      "Epoch 32: loss = 0.6617\n",
      "Epoch 33: loss = 0.6672\n",
      "Epoch 34: loss = 0.6307\n",
      "Epoch 35: loss = 0.6179\n",
      "Epoch 36: loss = 0.6201\n",
      "Epoch 37: loss = 0.6212\n",
      "Epoch 38: loss = 0.5927\n",
      "Epoch 39: loss = 0.6082\n",
      "Epoch 40: loss = 0.6217\n",
      "Epoch 41: loss = 0.5985\n",
      "Epoch 42: loss = 0.5901\n",
      "Epoch 43: loss = 0.5723\n",
      "Epoch 44: loss = 0.5634\n",
      "Epoch 45: loss = 0.5758\n",
      "Epoch 46: loss = 0.5930\n",
      "Epoch 47: loss = 0.5985\n",
      "Epoch 48: loss = 0.5767\n",
      "Epoch 49: loss = 0.5486\n",
      "Epoch 50: loss = 0.5391\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:51:02.329272Z",
     "start_time": "2025-05-06T17:50:57.920870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed_phrase = ' мой дядя самых честных правил'\n",
    "\n",
    "generated_phrases = [\n",
    "    generate_sample(\n",
    "        model,\n",
    "        seed_phrase,\n",
    "        max_length=500,\n",
    "        temperature=0.8  # можешь поэкспериментировать: 0.7–1.2\n",
    "    ).replace('<sos>', '')\n",
    "    for _ in range(10)\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:54:16.395313Z",
     "start_time": "2025-05-06T17:54:14.394351Z"
    }
   },
   "source": "print(generate_sample(model, ' мой дядя самых честных правил\\n', max_length=2000, temperature=0.4))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " мой дядя самых честных правил\n",
      "\n",
      "\n",
      "vi\n",
      "\n",
      "в том соседственных селений\n",
      "ему не нравились пиры;\n",
      "бежал он их беседы шумной,\n",
      "их разговор благоразумный\n",
      "о сенокосе, о вине,\n",
      "о псарне, о своей родне,\n",
      "конечно, не блистал ни чувством,\n",
      "ни поэтическим огнем,\n",
      "ни остротою, ни умом,\n",
      "ни общежития искусством;\n",
      "но от них оставляет отдохнуть.\n",
      "\n",
      "\n",
      "\n",
      "xlvi\n",
      "\n",
      "дай оглянусь. простите ж, сени,\n",
      "где дни мои текли в глуши,\n",
      "испрожен душою погружена,\n",
      "в сем сердце, полном одета счастья,\n",
      "хранит безмолвно между тем;\n",
      "так будто разрочь у риссотами;\n",
      "но разговор их милых жен\n",
      "гораздо меньше был умен.\n",
      "\n",
      "\n",
      "\n",
      "xii\n",
      "\n",
      "богат, хорош собою, ленский\n",
      "везде был принят как жених;\n",
      "таков обычай деревенский;\n",
      "все дочек прочили своих\n",
      "за полурусского соседа;\n",
      "взойдет ли он, тотчас беседа\n",
      "заводит слово стороной\n",
      "о скуке жизни холостой;\n",
      "зовут соседа к самовару,\n",
      "а дету самого утратя\n",
      "приготовляясь, денег развел,\n",
      "онегин рыхлый и брань,\n",
      "любви мечтательницы милой,\n",
      "но где его твой страстных стрела.\n",
      "\n",
      "\n",
      "\n",
      "xxxvi\n",
      "\n",
      "и так они старели оба.\n",
      "и отворились наконец\n",
      "перед супругом двери гроба,\n",
      "и нам досталось от него\n",
      "жеманство, – больше ничего.\n",
      "\n",
      "\n",
      "\n",
      "xxv\n",
      "\n",
      "итак, она вздохов страстей утра,\n",
      "задумавшись, моя душа,\n",
      "прелестным пальчиком писала\n",
      "на отуманенном стекле\n",
      "заветный вензель о да е.\n",
      "\n",
      "\n",
      "\n",
      "xxxviii\n",
      "\n",
      "и между тем душа в ней нельзя.\n",
      "но ей нельзя? но что не спит не смирить?\n",
      "\n",
      "\n",
      "\n",
      "xxv\n",
      "\n",
      "всё глуши чувства раз молодая,\n",
      "ее наперсница родная,\n",
      "судьбою вдаль занесена,\n",
      "с ней навсегда разлучена.\n",
      "как тень она без цели бродит,\n",
      "то смотрит в осьмнадцать лет.\n",
      "\n",
      "\n",
      "\n",
      "xii\n",
      "\n",
      "кип это все дела, всё бела?\n",
      "зато ж верная семья света\n",
      "в нем своим увое волненье\n",
      "в моей душе, в моей крови!\n",
      "с каким тяжелым умиленьем\n",
      "я наслаждаюсь дуновеньем\n",
      "в лицо мне веющей весны\n",
      "на утренней порой не хочут;\n",
      "на видет в мироческим возраженья,\n",
      "ночей невесты пламенный\n",
      "отменится он про собою.\n",
      "поэт, приди: я твой супруг!..»\n",
      "\n",
      "\n",
      "\n",
      "xxiii\n",
      "\n",
      "так он приятней, живой кармане\n",
      "трике нашего романа,\n",
      "в глуши, в деревне всё вам скучно,\n",
      "а мы… ничем мы не блестим,\n",
      "хоть вам и рады простодушно.\n",
      "\n",
      "зачем вы посетили нас?\n",
      "в глуши забытого селенья\n",
      "я никог\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
    "\n",
    "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:30:04.359276Z",
     "start_time": "2025-05-06T17:30:04.354620Z"
    }
   },
   "source": [
    "seed_phrase = ' мой дядя самых честных правил'"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:30:04.388292Z",
     "start_time": "2025-05-06T17:30:04.363278Z"
    }
   },
   "source": [
    "generated_phrases = # your code here\n",
    "\n",
    "# For example:\n",
    "\n",
    "# generated_phrases = [\n",
    "#     generate_sample(\n",
    "#         model,\n",
    "#         ' мой дядя самых честных правил',\n",
    "#         max_length=500,\n",
    "#         temperature=1.\n",
    "#     ).replace('<sos>', '')\n",
    "#     for _ in range(10)\n",
    "# ]"
   ],
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3861625285.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[28], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    generated_phrases = # your code here\u001B[0m\n\u001B[1;37m                        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:30:04.391294Z",
     "start_time": "2025-05-06T17:30:04.390295Z"
    }
   },
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "import json\n",
    "if 'generated_phrases' not in locals():\n",
    "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
    "\n",
    "for phrase in generated_phrases:\n",
    "\n",
    "    if not isinstance(phrase, str):\n",
    "        raise ValueError(\"The generated phrase should be a string\")\n",
    "\n",
    "    if len(phrase) != 500:\n",
    "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
    "\n",
    "    assert all([x in set(tokens) for x in set(list(phrase))]), 'Unknown tokens detected, check your submission!'\n",
    "    \n",
    "\n",
    "submission_dict = {\n",
    "    'token_to_idx': token_to_idx,\n",
    "    'generated_phrases': generated_phrases\n",
    "}\n",
    "\n",
    "with open('submission_dict.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print('File saved to `submission_dict.json`')\n",
    "# __________end of block__________"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "NLP HW Lab01_Poetry_generation.v5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
